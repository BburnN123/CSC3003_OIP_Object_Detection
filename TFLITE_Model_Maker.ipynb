{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUANWN3rpfC9"
   },
   "source": [
    "# 0. Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "146BB11JpfDA"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "42hJEdo_pfDB"
   },
   "outputs": [],
   "source": [
    "# Download and setup the path\n",
    "# Model name - Model that is going to save the checkpoint\n",
    "# Pretrained Model - Tensorflow 2 detection zoo\n",
    "# TF record - To generate the record file for the training and model\n",
    "# Label map name - the file that contain the labels\n",
    "\n",
    "CUSTOM_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hbPhYVy_pfDB"
   },
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': 'workspace',\n",
    "    'TENSORFLOW_MODEL_PATH':os.path.join('tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('workspace','images'),\n",
    "    'IMAGE_TEST_PATH' : os.path.join('workspace','images','test'),\n",
    "    'IMAGE_TRAIN_PATH' : os.path.join('workspace','images','train'),\n",
    "    'MODEL_PATH': os.path.join('workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'TFLITE_PATH':os.path.join('workspace','export-model',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    \n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LwhWZMI0pfDC"
   },
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HR-TfDGrpfDC"
   },
   "outputs": [],
   "source": [
    "# Create the path\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLU-rs_ipfDE"
   },
   "source": [
    "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/install/source_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-Cmz2edpfDE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install wget\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iA1DIq5OpfDE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clone tensorflow model gardern\n",
    "\n",
    "if not os.path.exists(os.path.join(paths['TENSORFLOW_MODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['TENSORFLOW_MODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJjMHbnDs3Tv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install Tensorflow Object Detection\n",
    "# Restart the kernal after this steps \n",
    "\n",
    "# Using anacoda \n",
    "!conda install -c anaconda protobuf -y\n",
    "\n",
    "!pip install cython\n",
    "!pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI\n",
    "    \n",
    "# Install the setup.py file in tensorflow\n",
    "!cd tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "!cd tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using verison 2.5.0\n",
    "!pip install tensorflow-gpu==2.5.0\n",
    "!pip install tensorflow-text==2.5.0\n",
    "\n",
    "!pip install typeguard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ensure the the script can run and is OK\n",
    "\n",
    "VERIFICATION_SCRIPT = os.path.join(paths['TENSORFLOW_MODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If object detection have no module is found, restart the kernal and run again\n",
    "import object_detection\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csofht2npfDE",
    "outputId": "ff5471b2-bed2-43f2-959c-327a706527b6"
   },
   "outputs": [],
   "source": [
    "# Unzip the folder\n",
    "wget.download(PRETRAINED_MODEL_URL)\n",
    "!move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5KJTnkfpfDC"
   },
   "source": [
    "# 2. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1BVDWo7pfDC"
   },
   "outputs": [],
   "source": [
    "# Insert the label here\n",
    "labels = [{'name':'dry syringe', 'id':1}, {'name':'dry plunger', 'id':2},\n",
    "          {'name':'wet syringe', 'id':3}, {'name':'wet plunger', 'id':4},\n",
    "          {'name':'dirty syringe', 'id':5}, {'name':'dirty plunger', 'id':6}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C88zyVELpfDC"
   },
   "source": [
    "# 3. Create TF records\n",
    "* Create 2 folder \"train\" and \"test\" under workspace/images and place your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPFToGZqpfDD",
    "outputId": "0ebb456f-aadc-4a1f-96e6-fbfec1923e1c"
   },
   "outputs": [],
   "source": [
    "# 80% train, 20% test\n",
    "\n",
    "!python {TF_RECORD_SCRIPT_NAME} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {TF_RECORD_SCRIPT_NAME} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT4QU7pLpfDE"
   },
   "source": [
    "# 4. Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOjuTFbwpfDF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga8gpNslpfDF"
   },
   "source": [
    "Update the config file accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9hRrO_ppfDF"
   },
   "outputs": [],
   "source": [
    "# Update the config file at the workspace/models/<modelname>/pipeline.config\n",
    "\n",
    "# num_classes - 2 (Depending on how many label you have)\n",
    "# fine_tune_checkpoint - (Path to the pre-trained-model checkpoint)\n",
    "# \"workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
    "\n",
    "# batch_size - 16 (Under train_config)\n",
    "\n",
    "# fine_tune_checkpoint_type - \"detection\"\n",
    "\n",
    "# For train_input_reader (Training)\n",
    "# label_map_path - \"workspace/annotations/label_map.pbtxt\"\n",
    "# input_path - \"workspace/annotations/train.record\" (File is generated from the generate_tfrecord.py)\n",
    "\n",
    "# For eval_input_reader (testing)\n",
    "# label_map_path - \"workspace/annotations/label_map.pbtxt\"\n",
    "# input_path - \"workspace/annotations/test.record\" (File is generated from the generate_tfrecord.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr3ON7xMpfDG"
   },
   "source": [
    "# 5. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-Y2UQmQpfDG"
   },
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['TENSORFLOW_MODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMP2XDfQpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4OXXi-ApfDH",
    "outputId": "117a0e83-012b-466e-b7a6-ccaa349ac5ab",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Copy the command and run this into the CMD line, ensure that you have run the correct environment\n",
    "# You are able to quit anytime\n",
    "# Best optimal value would be 0.04\n",
    "\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Tensorflow Board (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate your model reading or learning, you can start a tensorboard by activating your environment again\n",
    "\n",
    "```conda activate tensorflow```\n",
    "\n",
    "Change to the folder directory path\n",
    "\n",
    "```cd C:/tensorflow_build```\n",
    "\n",
    "Start the tensorboard and enter the link that is provided in the cmd \n",
    "(http://localhost:6006/) Port number might vary\n",
    "\n",
    "```tensorboard --logdir=models\\<folder name>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtUw73FHpfDK"
   },
   "source": [
    "# 7. Export to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XviMtewLpfDK"
   },
   "outputs": [],
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['TENSORFLOW_MODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "us86cjC4pfDL"
   },
   "outputs": [],
   "source": [
    "command = \"python {} \\\n",
    "--pipeline_config_path={} \\\n",
    "--trained_checkpoint_dir={} \\\n",
    "--output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1r5YO3rpfDL",
    "outputId": "5fcdf7a4-eee2-4365-f1ca-1751968379ea"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-xWpHN8pfDL",
    "outputId": "7f6bacd8-d077-43b5-c131-5b081fba24a4"
   },
   "outputs": [],
   "source": [
    "# Folder can be found at the export-model/tflite folder\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iJfYMbN6pfDL"
   },
   "outputs": [],
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,640,640,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8GwUeoFpfDL",
    "outputId": "fac43ea4-cc85-471b-a362-e994b06fd583"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbd7gqHMpfDL",
    "outputId": "7c8fe6d5-2415-4641-8548-39d425c202f7"
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command = \"tflite_convert \\\n",
    "# --saved_model_dir={} \\\n",
    "# --output_file={} \\\n",
    "# --input_shapes=1,640,640,3 \\\n",
    "# --input_arrays=normalized_input_image_tensor \\\n",
    "# --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "# --inference_type=QUANTIZED_UINT8 \\\n",
    "# --mean_values=128 \\\n",
    "# --std_dev_values=128 \\\n",
    "# --allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL)\n",
    "\n",
    "# !{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Label\n",
    "TFLITE_LABEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'labelmap.txt')\n",
    "# labels = [{'name':'dry syringe', 'id':1}, {'name':'dry plunger', 'id':2}]\n",
    "\n",
    "with open(TFLITE_LABEL, 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write(label['name'])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import seed\n",
    "from random import randint\n",
    "seed(1)\n",
    "\n",
    "def read_label_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    ret = {}\n",
    "    for row_number, content in enumerate(lines):\n",
    "        pair = re.split(r'[:\\s]+', content.strip(), maxsplit=1)\n",
    "        if len(pair) == 2 and pair[0].strip().isdigit():\n",
    "            ret[int(pair[0])] = pair[1].strip()\n",
    "        else:\n",
    "            ret[row_number] = content.strip()\n",
    "    return ret\n",
    "\n",
    "def run_inference(interpreter, image):\n",
    "    image = (np.float32(image) - input_mean) / input_std\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0]['index'], image)\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n",
    "    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n",
    "    # num_detections = interpreter.get_tensor(output_details[3]['index'])[0]\n",
    "    return boxes, classes, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_tflite_model(tflite_path):\n",
    "    test_image_paths = [os.path.join(paths[\"IMAGE_TEST_PATH\"],f) for f in os.listdir(paths[\"IMAGE_TEST_PATH\"]) if os.path.splitext(f)[1] == \".jpg\"]\n",
    "\n",
    "    # Creates tflite interpreter\n",
    "    interpreter = tf.lite.Interpreter(tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    interpreter.invoke() # warmup\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    height = input_details[0]['shape'][1]\n",
    "    width = input_details[0]['shape'][2]\n",
    "\n",
    "    input_mean = 127.5\n",
    "    input_std = 127.5\n",
    "\n",
    "    for image_path in test_image_paths:\n",
    "        print('Evaluating:', image_path)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        image_width, image_height = image.size\n",
    "\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        resized_image = image.resize((width, height))\n",
    "        np_image = np.asarray(resized_image)\n",
    "        input_tensor = np.expand_dims(np_image, axis=0)\n",
    "\n",
    "        # Run inference\n",
    "        boxes, classes, scores = run_inference(interpreter, input_tensor)\n",
    "\n",
    "\n",
    "        # Draw results on image    \n",
    "        labels = read_label_file(os.path.join(FROZEN_TFLITE_PATH, \"labelmap.txt\"))\n",
    "\n",
    "        # Generate the color accordingly the number of our label\n",
    "        colors = {}\n",
    "        for i in range(len(labels)):\n",
    "            value1 = randint(0, 255)\n",
    "            value2 = randint(0, 255)\n",
    "            value3 = randint(0, 255)\n",
    "            colors[i] = (value1, value2, value3)\n",
    "\n",
    "\n",
    "        %matplotlib inline\n",
    "        for i in range(len(boxes)):\n",
    "            if scores[i] > 0.5:\n",
    "                print(scores[i])\n",
    "                try:\n",
    "                    ymin = int(max(1, (boxes[i][0] * image_height)))\n",
    "                    xmin = int(max(1, (boxes[i][1] * image_width)))\n",
    "                    ymax = int(min(image_height, (boxes[i][2] * image_height)))\n",
    "                    xmax = int(min(image_width, (boxes[i][3] * image_width)))\n",
    "\n",
    "                    draw.rectangle((xmin, ymin, xmax, ymax), outline=colors[int(classes[i])])\n",
    "                    draw.rectangle((xmin, ymin, xmax, ymin-10), fill=colors[int(classes[i])])\n",
    "\n",
    "                    text = labels[int(classes[i])] + ' ' + str(scores[i]*100) + '%'\n",
    "                    draw.text((xmin+2, ymin-10), text, fill=(0,0,0), width=2)\n",
    "\n",
    "                except:\n",
    "                    print(\"Can't draw box\")\n",
    "                finally:\n",
    "                     display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_tflite_model(TFLITE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Export as TFLite TPU (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Refer to README.md*\n",
    "\n",
    "Reference\n",
    "https://gist.github.com/NobuoTsukamoto/f48df315be490dcf0c76375c2e04ddb1#file-export_tfv2_lite_models-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_quant_full_int_model(input_path, output_path, width, height):\n",
    "    input_width = width\n",
    "    input_height = height\n",
    "    \n",
    "    def representative_data_gen():\n",
    "        total_image = len([f for f in os.listdir(paths[\"IMAGE_TEST_PATH\"]) if os.path.splitext(f)[1] == \".jpg\"])\n",
    "        dataset_list = tf.data.Dataset.list_files(paths[\"IMAGE_TEST_PATH\"] + '\\\\*.jpg')\n",
    "        \n",
    "        for data in range(total_image):\n",
    "            image = next(iter(dataset_list))\n",
    "            image = tf.io.read_file(image)\n",
    "            image = tf.io.decode_jpeg(image, channels=3)\n",
    "            image = tf.image.resize(image, (input_height, input_width))\n",
    "            image = image[np.newaxis,:,:,:]\n",
    "            image = image - 127.5\n",
    "            image = image * 0.007843\n",
    "            yield [image]\n",
    "    \n",
    "    print(\"Loading model...\")\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(input_path, signature_keys=['serving_default'])\n",
    "    print(\"Loading done...\")\n",
    "    \n",
    "    converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\n",
    "    # converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    # converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    converter.inference_input_type = tf.uint8\n",
    "    converter.inference_output_type = tf.uint8\n",
    "    \n",
    "    print(\"Gathering representive data...\")\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "    \n",
    "    print(\"Converting...\")\n",
    "    tflite_full_integer_quant_model = converter.convert()\n",
    "    print(\"Converting Done\")\n",
    "    \n",
    "    open(output_path, \"wb\").write(tflite_full_integer_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Loading done...\n",
      "Gathering representive data...\n",
      "Converting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n",
      "WARNING:absl:For model outputs containing unsupported operations which cannot be quantized, the `inference_output_type` attribute will default to the original type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Done\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join(FROZEN_TFLITE_PATH, 'edge_quant.tflite')\n",
    "\n",
    "convert_quant_full_int_model(FROZEN_TFLITE_PATH, output_path, 640,640)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
