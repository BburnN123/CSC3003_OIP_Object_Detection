{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUANWN3rpfC9"
   },
   "source": [
    "# 0. Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "146BB11JpfDA"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "42hJEdo_pfDB"
   },
   "outputs": [],
   "source": [
    "# Download and setup the path\n",
    "# Model name - Model that is going to save the checkpoint\n",
    "# Pretrained Model - Tensorflow 2 detection zoo\n",
    "# TF record - To generate the record file for the training and model\n",
    "# Label map name - the file that contain the labels\n",
    "\n",
    "CUSTOM_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8' \n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "hbPhYVy_pfDB"
   },
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': 'workspace',\n",
    "    'TENSORFLOW_MODEL_PATH':os.path.join('tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('workspace','images'),\n",
    "    'IMAGE_DATASET':os.path.join('workspace','images', 'dataset'), \n",
    "    'IMAGE_TEST_PATH' : os.path.join('workspace','images','test'),\n",
    "    'IMAGE_TRAIN_PATH' : os.path.join('workspace','images','train'),\n",
    "    'MODEL_PATH': os.path.join('workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'TFLITE_PATH':os.path.join('workspace','export-model',CUSTOM_MODEL_NAME, 'tfliteexport')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "LwhWZMI0pfDC"
   },
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HR-TfDGrpfDC"
   },
   "outputs": [],
   "source": [
    "# Create the path\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLU-rs_ipfDE"
   },
   "source": [
    "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/install/source_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-Cmz2edpfDE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install wget\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iA1DIq5OpfDE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clone tensorflow model gardern\n",
    "\n",
    "if not os.path.exists(os.path.join(paths['TENSORFLOW_MODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['TENSORFLOW_MODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJjMHbnDs3Tv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install Tensorflow Object Detection\n",
    "# Restart the kernal after this steps \n",
    "\n",
    "# Using anacoda \n",
    "!conda install -c anaconda protobuf -y\n",
    "\n",
    "!pip install cython\n",
    "!pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI\n",
    "    \n",
    "# Install the setup.py file in tensorflow\n",
    "!cd tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "!cd tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using verison 2.5.0\n",
    "!pip install tensorflow-gpu==2.5.0\n",
    "!pip install tensorflow-text==2.5.0\n",
    "\n",
    "!pip install typeguard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ensure the the script can run and is OK\n",
    "\n",
    "VERIFICATION_SCRIPT = os.path.join(paths['TENSORFLOW_MODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If object detection have no module is found, restart the kernal and run again\n",
    "import object_detection\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csofht2npfDE",
    "outputId": "ff5471b2-bed2-43f2-959c-327a706527b6"
   },
   "outputs": [],
   "source": [
    "# Unzip the folder\n",
    "wget.download(PRETRAINED_MODEL_URL)\n",
    "!move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5KJTnkfpfDC"
   },
   "source": [
    "# 2. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1BVDWo7pfDC"
   },
   "outputs": [],
   "source": [
    "# Insert the label here\n",
    "labels = [{'name':'dry syringe', 'id':1}, {'name':'dry plunger', 'id':2},\n",
    "          {'name':'wet syringe', 'id':3}, {'name':'wet plunger', 'id':4},\n",
    "          {'name':'moist syringe', 'id':5}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C88zyVELpfDC"
   },
   "source": [
    "# 3. Create TF records\n",
    "* Create 2 folder \"train\" and \"test\" under workspace/images and place your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPFToGZqpfDD",
    "outputId": "0ebb456f-aadc-4a1f-96e6-fbfec1923e1c"
   },
   "outputs": [],
   "source": [
    "# 80% train, 20% test\n",
    "# use Data_Preparation.ipynb to clean up. Instruction at README.md\n",
    "\n",
    "!python {TF_RECORD_SCRIPT_NAME} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {TF_RECORD_SCRIPT_NAME} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT4QU7pLpfDE"
   },
   "source": [
    "# 4. Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOjuTFbwpfDF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga8gpNslpfDF"
   },
   "source": [
    "Update the config file accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9hRrO_ppfDF"
   },
   "outputs": [],
   "source": [
    "# Update the config file at the workspace/models/<modelname>/pipeline.config\n",
    "\n",
    "# num_classes - 2 (Depending on how many label you have)\n",
    "# fine_tune_checkpoint - (Path to the pre-trained-model checkpoint)\n",
    "# \"workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
    "\n",
    "# batch_size - 16 (Under train_config)\n",
    "\n",
    "# fine_tune_checkpoint_type - \"detection\"\n",
    "\n",
    "# For train_input_reader (Training)\n",
    "# label_map_path - \"workspace/annotations/label_map.pbtxt\"\n",
    "# input_path - \"workspace/annotations/train.record\" (File is generated from the generate_tfrecord.py)\n",
    "\n",
    "# For eval_input_reader (testing)\n",
    "# label_map_path - \"workspace/annotations/label_map.pbtxt\"\n",
    "# input_path - \"workspace/annotations/test.record\" (File is generated from the generate_tfrecord.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr3ON7xMpfDG"
   },
   "source": [
    "# 5. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "B-Y2UQmQpfDG"
   },
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['TENSORFLOW_MODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "jMP2XDfQpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4OXXi-ApfDH",
    "outputId": "117a0e83-012b-466e-b7a6-ccaa349ac5ab",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python tensorflow\\models\\research\\object_detection\\model_main_tf2.py --model_dir=workspace\\models\\ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8 --pipeline_config_path=workspace\\models\\ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\\pipeline.config\n"
     ]
    }
   ],
   "source": [
    "# Copy the command and run this into the CMD line, ensure that you have run the correct environment\n",
    "# You are able to quit anytime\n",
    "# Best optimal value would be 0.3 and below\n",
    "\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Tensorflow Board (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate your model reading or learning, you can start a tensorboard by activating your environment again\n",
    "\n",
    "```conda activate tensorflow```\n",
    "\n",
    "Change to the folder directory path\n",
    "\n",
    "```cd C:/tensorflow_build```\n",
    "\n",
    "Start the tensorboard and enter the link that is provided in the cmd \n",
    "(http://localhost:6006/) Port number might vary\n",
    "\n",
    "```tensorboard --logdir=workspace\\models\\<folder name>```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tensorboard --logdir={}\".format(paths['CHECKPOINT_PATH'])\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtUw73FHpfDK"
   },
   "source": [
    "# 7. Export to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "XviMtewLpfDK"
   },
   "outputs": [],
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['TENSORFLOW_MODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "us86cjC4pfDL"
   },
   "outputs": [],
   "source": [
    "command = \"python {} \\\n",
    "--pipeline_config_path={} \\\n",
    "--trained_checkpoint_dir={} \\\n",
    "--output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1r5YO3rpfDL",
    "outputId": "5fcdf7a4-eee2-4365-f1ca-1751968379ea",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-xWpHN8pfDL",
    "outputId": "7f6bacd8-d077-43b5-c131-5b081fba24a4"
   },
   "outputs": [],
   "source": [
    "# Folder can be found at the export-model/tflite folder\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "iJfYMbN6pfDL"
   },
   "outputs": [],
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,640,640,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command = \"tflite_convert \\\n",
    "# --output_file={} \\\n",
    "# --saved_model_dir={} \\\n",
    "# --inference_type=QUANTIZED_UINT8 \\\n",
    "# --input_shape= 1,300,300,3 \\\n",
    "# --input_array = normalized_input_image_tensor\\\n",
    "# --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "# --mean_values=128 --std_dev_values=128 \\\n",
    "# --default_ranges_min=0 --default_ranges_max=255 \\\n",
    "# --allow_custom_ops\".format(TFLITE_MODEL, FROZEN_TFLITE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8GwUeoFpfDL",
    "outputId": "fac43ea4-cc85-471b-a362-e994b06fd583",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbd7gqHMpfDL",
    "outputId": "7c8fe6d5-2415-4641-8548-39d425c202f7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Label\n",
    "# Label can be found at Section 2. Create Label Map\n",
    "TFLITE_LABEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'labelmap.txt')\n",
    "# labels = [{'name':'dry syringe', 'id':1}, {'name':'dry plunger', 'id':2}]\n",
    "\n",
    "with open(TFLITE_LABEL, 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write(label['name'])\n",
    "        f.write('\\n')\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the precision\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python tensorflow\\models\\research\\object_detection\\model_main_tf2.py --model_dir=workspace\\models\\ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8 --pipeline_config_path=workspace\\models\\ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\\pipeline.config --checkpoint_dir=workspace\\models\\ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An eval folder will be created and can be further eval by entering this command \"tensorboard --logdir=.\" at the eval folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.Evaluate the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluting the picture\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import seed\n",
    "from random import randint\n",
    "seed(1)\n",
    "\n",
    "test_image_paths = [os.path.join(paths[\"IMAGE_TEST_PATH\"],f) for f in os.listdir(paths[\"IMAGE_TEST_PATH\"]) if os.path.splitext(f)[1] == \".jpg\"]\n",
    "\n",
    "def read_label_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    ret = {}\n",
    "    for row_number, content in enumerate(lines):\n",
    "        pair = re.split(r'[:\\s]+', content.strip(), maxsplit=1)\n",
    "        if len(pair) == 2 and pair[0].strip().isdigit():\n",
    "            ret[int(pair[0])] = pair[1].strip()\n",
    "        else:\n",
    "            ret[row_number] = content.strip()\n",
    "    return ret\n",
    "\n",
    "def run_inference(interpreter, image):\n",
    "    image = (np.float32(image) - input_mean) / input_std\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], image)\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n",
    "    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n",
    "    # num_detections = interpreter.get_tensor(output_details[3]['index'])[0]\n",
    "    return boxes, classes, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "input_mean = 127.5\n",
    "input_std = 127.5\n",
    "\n",
    "# Creates tflite interpreter\n",
    "interpreter = tf.lite.Interpreter(TFLITE_MODEL)\n",
    "interpreter.allocate_tensors()\n",
    "interpreter.invoke() # warmup\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "height = input_details[0]['shape'][1]\n",
    "width = input_details[0]['shape'][2]\n",
    "\n",
    "grayscale = True\n",
    "\n",
    "for image_path in test_image_paths:\n",
    "    print('Evaluating:', image_path)\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    if grayscale:\n",
    "        image = image.convert('RGB') # Convert to RGB first\n",
    "        \n",
    "    \n",
    "    image_width, image_height = image.size\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "        \n",
    "    resized_image = image.resize((width, height))\n",
    "    np_image = np.asarray(resized_image)\n",
    "    input_tensor = np.expand_dims(np_image, axis=0)\n",
    "\n",
    "    # Run inference\n",
    "    boxes, classes, scores = run_inference(interpreter, input_tensor)\n",
    "\n",
    "\n",
    "    # Draw results on image    \n",
    "    labels = read_label_file(os.path.join(FROZEN_TFLITE_PATH, \"labelmap.txt\"))\n",
    "\n",
    "    # Generate the color accordingly the number of our label\n",
    "    colors = {}\n",
    "    for i in range(len(labels)):\n",
    "        value1 = randint(0, 255)\n",
    "        value2 = randint(0, 255)\n",
    "        value3 = randint(0, 255)\n",
    "        colors[i] = (value1, value2, value3)\n",
    "\n",
    "\n",
    "    %matplotlib inline\n",
    "    for i in range(len(boxes)):\n",
    "        if scores[i] > 0.5:\n",
    "          \n",
    "            try:\n",
    "                ymin = int(max(1, (boxes[i][0] * image_height)))\n",
    "                xmin = int(max(1, (boxes[i][1] * image_width)))\n",
    "                ymax = int(min(image_height, (boxes[i][2] * image_height)))\n",
    "                xmax = int(min(image_width, (boxes[i][3] * image_width)))\n",
    "\n",
    "                draw.rectangle((xmin, ymin, xmax, ymax), outline=colors[int(classes[i])])\n",
    "                draw.rectangle((xmin, ymin, xmax, ymin-10), fill=colors[int(classes[i])])\n",
    "\n",
    "                text = labels[int(classes[i])] + ' ' + str(scores[i]*100) + '%'\n",
    "                draw.text((xmin+2, ymin-10), text, fill=(0,0,0), width=2)\n",
    "                print(\"Score for {}\".format(text) )\n",
    "\n",
    "            except:\n",
    "                print(\"Can't draw box\")\n",
    "            finally:\n",
    "                 display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Export as TFLite TPU (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Refer to README.md*\n",
    "\n",
    "Reference\n",
    "https://gist.github.com/NobuoTsukamoto/f48df315be490dcf0c76375c2e04ddb1#file-export_tfv2_lite_models-ipynb\n",
    "\n",
    "Use \"ssd_mobilenet_v2_320x320_coco17_tpu-8\" only.\n",
    "\n",
    "The size input of 300 x 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTIZE_TPU_PATH = os.path.join(FROZEN_TFLITE_PATH, 'detect_quantize_edge.tflite')\n",
    "QUANTIZE_TFLITE_PATH = os.path.join(FROZEN_TFLITE_PATH, 'detect_quantize.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_quant_full_int_model(input_path, output_path, width, height):\n",
    "    input_width = width\n",
    "    input_height = height\n",
    "    \n",
    "    def representative_data_gen():\n",
    "        total_image = len([f for f in os.listdir(paths[\"IMAGE_TEST_PATH\"]) if os.path.splitext(f)[1] == \".jpg\"])\n",
    "        dataset_list = tf.data.Dataset.list_files(paths[\"IMAGE_TEST_PATH\"] + '\\\\*.jpg')\n",
    "        \n",
    "        for data in range(total_image):\n",
    "            image = next(iter(dataset_list))\n",
    "            image = tf.io.read_file(image)\n",
    "            image = tf.io.decode_jpeg(image, channels=3)\n",
    "            image = tf.image.resize(image, (input_height, input_width))\n",
    "#             image = image[np.newaxis,:,:,:]\n",
    "#             image = image - 127.5\n",
    "#             image = image * 0.007843\n",
    "            image = tf.cast(image / 255., tf.float32)\n",
    "            image = tf.expand_dims(image, 0)\n",
    "            \n",
    "            yield [image]\n",
    "\n",
    "    \n",
    "    print(\"Loading model...\")\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(input_path, signature_keys=['serving_default'])\n",
    "    print(\"Loading done...\")\n",
    "    \n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    # converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    converter.inference_input_type = tf.uint8\n",
    "    converter.inference_output_type = tf.uint8\n",
    "    \n",
    "    print(\"Gathering representive data...\")\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "    \n",
    "    print(\"Converting...\")\n",
    "    tflite_full_integer_quant_model = converter.convert()\n",
    "    print(\"Converting Done\")\n",
    "    \n",
    "    open(output_path, \"wb\").write(tflite_full_integer_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convert_quant_full_int_model(FROZEN_TFLITE_PATH, QUANTIZE_TPU_PATH, 300,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
